import streamlit as st
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
import requests
import time
import json
import os

# Health check endpoint
if st.query_params.get("health") == "check":
    st.write("OK")
    st.stop()

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 1. AutenticaciÃ³n a Google Sheets
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
SCOPES = ["https://www.googleapis.com/auth/spreadsheets.readonly"]

# ConfiguraciÃ³n de credenciales
try:
    if os.getenv("GOOGLE_CREDENTIALS"):
        # ProducciÃ³n - DigitalOcean
        creds_info = json.loads(os.getenv("GOOGLE_CREDENTIALS"))
        creds = Credentials.from_service_account_info(creds_info, scopes=SCOPES)
    else:
        # Desarrollo local
        creds = Credentials.from_service_account_file("credentials.json", scopes=SCOPES)
    
    gc = gspread.authorize(creds)
except Exception as e:
    st.error(f"Error de autenticaciÃ³n: {e}")
    st.stop()

# Obtener configuraciÃ³n - Variables de entorno o secrets locales
SHEET_ID = os.getenv("SHEET_ID") or st.secrets.get("SHEET_ID")
N8N_WEBHOOK = os.getenv("N8N_WEBHOOK") or st.secrets.get("N8N_WEBHOOK")
X_API_KEY = os.getenv("X_API_KEY") or st.secrets.get("X_API_KEY")

# Verificar que las variables estÃ©n configuradas
if not all([SHEET_ID, N8N_WEBHOOK, X_API_KEY]):
    st.error("âŒ Variables de entorno no configuradas. Verifica SHEET_ID, N8N_WEBHOOK y X_API_KEY")
    st.info("ğŸ’¡ En desarrollo local, usa el archivo .streamlit/secrets.toml")
    st.stop()

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 2. Funciones auxiliares
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
@st.cache_data(ttl=60)  # Cache por 1 minuto para detectar cambios mÃ¡s rÃ¡pido
def get_sheet_data():
    """Obtiene datos de Google Sheets con cache"""
    try:
        sheet = gc.open_by_key(SHEET_ID).sheet1
        data = sheet.get_all_records()
        return pd.DataFrame(data)
    except Exception as e:
        st.error(f"Error al obtener datos: {e}")
        return pd.DataFrame()

def send_to_n8n(username, posts):
    """EnvÃ­a username y cantidad de posts a n8n webhook y retorna cuando termine."""
    try:
        headers = {
            'Content-Type': 'application/json',
            'X-API-KEY': X_API_KEY
        }
        
        payload = {
            "username": username,
            "posts": posts
        }
        
        response = requests.post(
            N8N_WEBHOOK, 
            json=payload, 
            headers=headers,
            timeout=300
        )
        
        return response.status_code == 200, response.text
        
    except requests.exceptions.Timeout:
        return False, "Timeout - El scraping puede estar en proceso"
    except Exception as e:
        return False, f"Error: {str(e)}"

def wait_for_new_data(initial_count, usernames_count, max_wait_time=300):
    """Espera hasta que aparezcan nuevos datos en el sheet o se agote el tiempo"""
    start_time = time.time()
    
    # Crear un placeholder para mostrar el progreso
    progress_placeholder = st.empty()
    
    while time.time() - start_time < max_wait_time:
        # Limpiar cache para obtener datos frescos
        get_sheet_data.clear()
        current_df = get_sheet_data()
        current_count = len(current_df)
        
        elapsed_time = int(time.time() - start_time)
        progress_placeholder.info(f"â³ Esperando nuevos datos... ({elapsed_time}s / {max_wait_time}s)")
        
        # Si hay nuevos datos (aproximadamente)
        if current_count > initial_count:
            progress_placeholder.empty()
            return True, current_df
            
        time.sleep(5)  # Esperar 5 segundos antes de verificar nuevamente
    
    progress_placeholder.empty()
    return False, get_sheet_data()

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 3. ConfiguraciÃ³n de la aplicaciÃ³n Streamlit
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
st.set_page_config(
    page_title="Demo Instagram Profile Scraper",
    page_icon="ğŸ“¸",
    layout="wide"
)

st.title("ğŸ“¸ Demo Instagram Profile Scraper")
st.markdown("### Cliente: Tomas de la Serna")

# Inicializar estado de la sesiÃ³n
if 'scraping_completed' not in st.session_state:
    st.session_state.scraping_completed = False
if 'last_scraped_data' not in st.session_state:
    st.session_state.last_scraped_data = None

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 4. SecciÃ³n de inputs
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
col1, col2 = st.columns([3, 1])

with col1:
    # Campo para mÃºltiples usernames (uno por lÃ­nea)
    raw_usernames = st.text_area(
        "Usernames de Instagram (hasta 5, uno por lÃ­nea)",
        placeholder="cristiano\nnatgeo\nnasa",
        help="Ingresa hasta 5 usernames, uno por lÃ­nea, sin @ ni URL completa",
        height=120
    )

    # Campo para cantidad de posts a scrapear (mÃ¡x. 10)
    num_posts = st.number_input(
        "Cantidad de posts a scrapear (mÃ¡x. 10)",
        min_value=1,
        max_value=10,
        value=5,
        help="Ingresa un nÃºmero entre 1 y 10"
    )

with col2:
    st.markdown("<br><br>", unsafe_allow_html=True)  # Un poco de espacio vertical
    
    # BotÃ³n de scraping
    scrape_button = st.button("ğŸš€ Iniciar Scraping", type="primary", disabled=st.session_state.get('scraping_in_progress', False))
    
    # BotÃ³n de refresh
    st.markdown("<br>", unsafe_allow_html=True)
    if st.button("ğŸ”„ Refrescar", help="Limpiar datos y empezar de nuevo"):
        st.session_state.scraping_completed = False
        st.session_state.last_scraped_data = None
        st.session_state.scraping_in_progress = False
        get_sheet_data.clear()
        st.rerun()

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 5. Procesamiento del scraping
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
if scrape_button:
    # Parsear y limpiar lista de usernames (separados por lÃ­neas)
    usernames_list = [
        u.strip().replace('@', '').replace('instagram.com/', '')
        for u in raw_usernames.split("\n") if u.strip()
    ]
    
    # Validaciones
    if not usernames_list:
        st.warning("âš ï¸ Por favor ingresa al menos un username.")
    elif len(usernames_list) > 5:
        st.warning("âš ï¸ Has ingresado mÃ¡s de 5 usernames. Reduce la lista a un mÃ¡ximo de 5.")
    else:
        # Marcar que el scraping estÃ¡ en progreso
        st.session_state.scraping_in_progress = True
        st.session_state.scraping_completed = False
        
        # Obtener conteo inicial de datos
        initial_df = get_sheet_data()
        initial_count = len(initial_df)
        
        # Ejecutar scraping
        errores = []
        with st.spinner("â³ Enviando solicitudes a N8N..."):
            for user in usernames_list:
                success, message = send_to_n8n(user, int(num_posts))
                if not success:
                    errores.append(f"@{user}: {message}")

        # Si hubo errores en el envÃ­o
        if errores:
            st.error("âŒ Ocurrieron errores durante el envÃ­o:")
            for err in errores:
                st.write(f"- {err}")
            st.session_state.scraping_in_progress = False
        else:
            st.success("âœ… Solicitudes enviadas correctamente. Esperando resultados...")
            
            # Esperar a que aparezcan nuevos datos
            success, final_df = wait_for_new_data(initial_count, len(usernames_list))
            
            if success:
                st.success("ğŸ‰ Â¡Scraping realizado con Ã©xito para todos los usernames!")
                st.session_state.scraping_completed = True
                st.session_state.last_scraped_data = final_df
            else:
                st.warning("âš ï¸ El scraping puede estar tomando mÃ¡s tiempo del esperado. Los datos aparecerÃ¡n cuando estÃ© listo.")
                st.info("ğŸ’¡ Puedes usar el botÃ³n 'Refrescar' para verificar si llegaron nuevos datos.")
            
            st.session_state.scraping_in_progress = False

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 6. Mostrar datos scrapeados solo si el scraping fue exitoso
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
st.markdown("---")
st.subheader("ğŸ“Š Datos Scrapeados")

# Mostrar datos y botÃ³n de descarga solo si el scraping fue completado exitosamente
if st.session_state.scraping_completed and st.session_state.last_scraped_data is not None:
    df = st.session_state.last_scraped_data
    
    if not df.empty:
        # Mostrar informaciÃ³n sobre los datos
        st.info(f"ğŸ“ˆ Se encontraron {len(df)} registros en total")
        
        # BotÃ³n de descarga
        csv = df.to_csv(index=False)
        st.download_button(
            label="ğŸ“¥ Descargar CSV",
            data=csv,
            file_name=f"instagram_data_{time.strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
        
        # Opcionalmente, mostrar preview de los datos
        with st.expander("ğŸ‘ï¸ Ver preview de los datos"):
            st.dataframe(df.head(10), use_container_width=True)
    else:
        st.error("âŒ No se pudieron obtener los datos scrapeados")
else:
    st.info("ğŸ“ Los datos aparecerÃ¡n aquÃ­ una vez que el scraping estÃ© completo y exitoso.")

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 7. Footer
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
st.markdown("---")
st.markdown("**ğŸ”§ Demo Instagram Scraper** - AutomatizaciÃ³n con n8n + Google Sheets")
